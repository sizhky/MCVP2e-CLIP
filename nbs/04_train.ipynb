{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "> Dev notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# | hide\\n%reload_ext autoreload\\n%reload_ext nb_black\\n%autoreload 2\\nfrom nbdev.showdoc import *\\nimport sys\\n\\n__root = \\\"../\\\"\\nsys.path.append(__root)\";\n",
       "                var nbb_formatted_code = \"# | hide\\n%reload_ext autoreload\\n%reload_ext nb_black\\n%autoreload 2\\nfrom nbdev.showdoc import *\\nimport sys\\n\\n__root = \\\"../\\\"\\nsys.path.append(__root)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | hide\n",
    "%reload_ext autoreload\n",
    "%reload_ext nb_black\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *\n",
    "import sys\n",
    "\n",
    "__root = \"../\"\n",
    "sys.path.append(__root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import itertools\\nfrom torch_snippets import *\\nfrom clip.core import download_flickr8k_from_kaggle\\nfrom clip.config import ClipConfig\\nfrom clip.dataset import CLIPDataset\\nfrom clip.models import CLIP\";\n",
       "                var nbb_formatted_code = \"import itertools\\nfrom torch_snippets import *\\nfrom clip.core import download_flickr8k_from_kaggle\\nfrom clip.config import ClipConfig\\nfrom clip.dataset import CLIPDataset\\nfrom clip.models import CLIP\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "from torch_snippets import *\n",
    "from clip.core import download_flickr8k_from_kaggle\n",
    "from clip.config import ClipConfig\n",
    "from clip.dataset import CLIPDataset\n",
    "from clip.models import CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/23/23 21:11:16] </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">INFO    </span> Loaded key from <span style=\"color: #800080; text-decoration-color: #800080\">/home/yyr/Downloads/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">kaggle.json</span>                                                                      <a href=\"file:///mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/nbs/../clip/core.py:15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">core.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/nbs/../clip/core.py:15#load_kaggle_key:15\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">load_kaggle_key:15</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/23/23 21:11:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[2;33mINFO    \u001b[0m Loaded key from \u001b[35m/home/yyr/Downloads/\u001b[0m\u001b[95mkaggle.json\u001b[0m                                                                      \u001b]8;id=334599;file:///mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/nbs/../clip/core.py:15\u001b\\\u001b[2mcore.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=224002;file:///mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/nbs/../clip/core.py:15#load_kaggle_key:15\u001b\\\u001b[2mload_kaggle_key:15\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">INFO    </span> Data is already downloaded at <span style=\"color: #800080; text-decoration-color: #800080\">/home/yyr/Zapdos/ml-datasets/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">flickr-8k-kaggle</span>                            <a href=\"file:///mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/nbs/../clip/core.py:24\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">core.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/nbs/../clip/core.py:24#download_flickr8k_from_kaggle:24\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">download_flickr8k_from_kaggle:24</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[2;33mINFO    \u001b[0m Data is already downloaded at \u001b[35m/home/yyr/Zapdos/ml-datasets/\u001b[0m\u001b[95mflickr-8k-kaggle\u001b[0m                            \u001b]8;id=411276;file:///mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/nbs/../clip/core.py:24\u001b\\\u001b[2mcore.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=751506;file:///mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/nbs/../clip/core.py:24#download_flickr8k_from_kaggle:24\u001b\\\u001b[2mdownload_flickr8k_from_kaggle:24\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# | master\\nkaggle_json_path = P(\\\"/home/yyr/Downloads/kaggle.json\\\")\\ndata_download_path = P(\\\"/home/yyr/Zapdos/ml-datasets/flickr-8k-kaggle/\\\")\\ndownload_flickr8k_from_kaggle(kaggle_json_path, data_download_path)\\n\\ndf = pd.read_csv(data_download_path / \\\"captions.txt\\\")\\ndf[\\\"id\\\"] = [id_ for id_ in range(len(df) // 5) for _ in range(5)]\\ndf.to_csv(data_download_path / \\\"captions.csv\\\")\";\n",
       "                var nbb_formatted_code = \"# | master\\nkaggle_json_path = P(\\\"/home/yyr/Downloads/kaggle.json\\\")\\ndata_download_path = P(\\\"/home/yyr/Zapdos/ml-datasets/flickr-8k-kaggle/\\\")\\ndownload_flickr8k_from_kaggle(kaggle_json_path, data_download_path)\\n\\ndf = pd.read_csv(data_download_path / \\\"captions.txt\\\")\\ndf[\\\"id\\\"] = [id_ for id_ in range(len(df) // 5) for _ in range(5)]\\ndf.to_csv(data_download_path / \\\"captions.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | master\n",
    "kaggle_json_path = P(\"/home/yyr/Downloads/kaggle.json\")\n",
    "data_download_path = P(\"/home/yyr/Zapdos/ml-datasets/flickr-8k-kaggle/\")\n",
    "download_flickr8k_from_kaggle(kaggle_json_path, data_download_path)\n",
    "\n",
    "df = pd.read_csv(data_download_path / \"captions.txt\")\n",
    "df[\"id\"] = [id_ for id_ in range(len(df) // 5) for _ in range(5)]\n",
    "df.to_csv(data_download_path / \"captions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"config = ClipConfig()\\nconfig.image_path = data_download_path / \\\"Images\\\"\\nconfig.captions_csv_path = data_download_path / \\\"captions.csv\\\"\\nconfig.debug = False  # Switch to True case you want to reduce the dataset size\";\n",
       "                var nbb_formatted_code = \"config = ClipConfig()\\nconfig.image_path = data_download_path / \\\"Images\\\"\\nconfig.captions_csv_path = data_download_path / \\\"captions.csv\\\"\\nconfig.debug = False  # Switch to True case you want to reduce the dataset size\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = ClipConfig()\n",
    "config.image_path = data_download_path / \"Images\"\n",
    "config.captions_csv_path = data_download_path / \"captions.csv\"\n",
    "config.debug = False  # Switch to True case you want to reduce the dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/23/23 21:11:47] </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">INFO    </span> Creating encoded captions for train dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span> - Completed in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28.63</span> s                                                <a href=\"file:///home/yyr/anaconda3/envs/mcvp-book/lib/python3.8/contextlib.py:120\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">contextlib.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/yyr/anaconda3/envs/mcvp-book/lib/python3.8/contextlib.py:120#__exit__:120\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__exit__:120</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/23/23 21:11:47]\u001b[0m\u001b[2;36m \u001b[0m\u001b[2;33mINFO    \u001b[0m Creating encoded captions for train dataset\u001b[33m...\u001b[0m - Completed in \u001b[1;36m28.63\u001b[0m s                                                \u001b]8;id=455140;file:///home/yyr/anaconda3/envs/mcvp-book/lib/python3.8/contextlib.py:120\u001b\\\u001b[2mcontextlib.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=136547;file:///home/yyr/anaconda3/envs/mcvp-book/lib/python3.8/contextlib.py:120#__exit__:120\u001b\\\u001b[2m__exit__:120\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/23/23 21:11:57] </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">INFO    </span> Creating encoded captions for valid dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span> - Completed in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.96</span> s                                                 <a href=\"file:///home/yyr/anaconda3/envs/mcvp-book/lib/python3.8/contextlib.py:120\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">contextlib.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/yyr/anaconda3/envs/mcvp-book/lib/python3.8/contextlib.py:120#__exit__:120\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__exit__:120</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/23/23 21:11:57]\u001b[0m\u001b[2;36m \u001b[0m\u001b[2;33mINFO    \u001b[0m Creating encoded captions for valid dataset\u001b[33m...\u001b[0m - Completed in \u001b[1;36m8.96\u001b[0m s                                                 \u001b]8;id=272822;file:///home/yyr/anaconda3/envs/mcvp-book/lib/python3.8/contextlib.py:120\u001b\\\u001b[2mcontextlib.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=78757;file:///home/yyr/anaconda3/envs/mcvp-book/lib/python3.8/contextlib.py:120#__exit__:120\u001b\\\u001b[2m__exit__:120\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# trn_dl, val_dl = build_clip_data_loaders(config)\\ntrn_ds, val_ds = CLIPDataset.train_test_split(config)\\n\\nmodel = CLIP(config).to(config.device)\\nparams = [\\n    {\\\"params\\\": model.image_encoder.parameters(), \\\"lr\\\": config.image_encoder_lr},\\n    {\\\"params\\\": model.text_encoder.parameters(), \\\"lr\\\": config.text_encoder_lr},\\n    {\\n        \\\"params\\\": itertools.chain(\\n            model.image_projection.parameters(), model.text_projection.parameters()\\n        ),\\n        \\\"lr\\\": config.head_lr,\\n        \\\"weight_decay\\\": config.weight_decay,\\n    },\\n]\\noptimizer = torch.optim.AdamW(params, weight_decay=0.0)\\nlr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\\n    optimizer, mode=\\\"min\\\", patience=config.patience, factor=config.factor\\n)\";\n",
       "                var nbb_formatted_code = \"# trn_dl, val_dl = build_clip_data_loaders(config)\\ntrn_ds, val_ds = CLIPDataset.train_test_split(config)\\n\\nmodel = CLIP(config).to(config.device)\\nparams = [\\n    {\\\"params\\\": model.image_encoder.parameters(), \\\"lr\\\": config.image_encoder_lr},\\n    {\\\"params\\\": model.text_encoder.parameters(), \\\"lr\\\": config.text_encoder_lr},\\n    {\\n        \\\"params\\\": itertools.chain(\\n            model.image_projection.parameters(), model.text_projection.parameters()\\n        ),\\n        \\\"lr\\\": config.head_lr,\\n        \\\"weight_decay\\\": config.weight_decay,\\n    },\\n]\\noptimizer = torch.optim.AdamW(params, weight_decay=0.0)\\nlr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\\n    optimizer, mode=\\\"min\\\", patience=config.patience, factor=config.factor\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# trn_dl, val_dl = build_clip_data_loaders(config)\n",
    "trn_ds, val_ds = CLIPDataset.train_test_split(config)\n",
    "\n",
    "model = CLIP(config).to(config.device)\n",
    "params = [\n",
    "    {\"params\": model.image_encoder.parameters(), \"lr\": config.image_encoder_lr},\n",
    "    {\"params\": model.text_encoder.parameters(), \"lr\": config.text_encoder_lr},\n",
    "    {\n",
    "        \"params\": itertools.chain(\n",
    "            model.image_projection.parameters(), model.text_projection.parameters()\n",
    "        ),\n",
    "        \"lr\": config.head_lr,\n",
    "        \"weight_decay\": config.weight_decay,\n",
    "    },\n",
    "]\n",
    "optimizer = torch.optim.AdamW(params, weight_decay=0.0)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", patience=config.patience, factor=config.factor\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4048' max='4048' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4048/4048 1:03:39, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.898400</td>\n",
       "      <td>2.246151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.095200</td>\n",
       "      <td>2.187405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.677100</td>\n",
       "      <td>2.177920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>2.218436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.388600</td>\n",
       "      <td>2.283489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.321500</td>\n",
       "      <td>2.317244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.243800</td>\n",
       "      <td>2.431228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.221200</td>\n",
       "      <td>2.317610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='253' max='253' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [253/253 01:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.3055901527404785,\n",
       " 'eval_runtime': 83.5751,\n",
       " 'eval_samples_per_second': 96.799,\n",
       " 'eval_steps_per_second': 3.027,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"from transformers import Trainer, TrainingArguments\\n\\n\\n# Define TrainingArguments\\ntraining_args = TrainingArguments(\\n    output_dir=\\\"./results\\\",  # Output directory where checkpoints and logs will be saved.\\n    num_train_epochs=config.epochs,  # Total number of training epochs.\\n    per_device_train_batch_size=config.batch_size,  # Batch size per GPU.\\n    per_device_eval_batch_size=config.batch_size,  # Batch size for evaluation per GPU.\\n    evaluation_strategy=\\\"steps\\\",  # Evaluation strategy (steps, epoch).\\n    logging_strategy=\\\"steps\\\",  # Logging strategy (steps, epoch).\\n    save_strategy=\\\"steps\\\",  # Save strategy (steps, epoch).\\n    save_total_limit=2,  # Limit the total amount of checkpoints.\\n    learning_rate=5e-5,  # Learning rate.\\n    logging_steps=config.save_eval_and_logging_steps,\\n    save_steps=config.save_eval_and_logging_steps,  # Save checkpoints every N steps.\\n    eval_steps=config.save_eval_and_logging_steps,  # Evaluate every N steps.\\n    logging_dir=\\\"./logs\\\",  # Directory for storing logs.\\n    metric_for_best_model=\\\"loss\\\",\\n    label_names=[\\\"image\\\", \\\"input_ids\\\"],\\n)\\n\\n# Create Trainer\\ntrainer = Trainer(\\n    model=model,\\n    args=training_args,\\n    train_dataset=trn_ds,\\n    eval_dataset=val_ds,\\n    optimizers=(optimizer, lr_scheduler),  # Pass your custom optimizer here.\\n)\\n# Train the model\\ntrainer.train()\\n\\n# Evaluate the model\\ntrainer.evaluate()\";\n",
       "                var nbb_formatted_code = \"from transformers import Trainer, TrainingArguments\\n\\n\\n# Define TrainingArguments\\ntraining_args = TrainingArguments(\\n    output_dir=\\\"./results\\\",  # Output directory where checkpoints and logs will be saved.\\n    num_train_epochs=config.epochs,  # Total number of training epochs.\\n    per_device_train_batch_size=config.batch_size,  # Batch size per GPU.\\n    per_device_eval_batch_size=config.batch_size,  # Batch size for evaluation per GPU.\\n    evaluation_strategy=\\\"steps\\\",  # Evaluation strategy (steps, epoch).\\n    logging_strategy=\\\"steps\\\",  # Logging strategy (steps, epoch).\\n    save_strategy=\\\"steps\\\",  # Save strategy (steps, epoch).\\n    save_total_limit=2,  # Limit the total amount of checkpoints.\\n    learning_rate=5e-5,  # Learning rate.\\n    logging_steps=config.save_eval_and_logging_steps,\\n    save_steps=config.save_eval_and_logging_steps,  # Save checkpoints every N steps.\\n    eval_steps=config.save_eval_and_logging_steps,  # Evaluate every N steps.\\n    logging_dir=\\\"./logs\\\",  # Directory for storing logs.\\n    metric_for_best_model=\\\"loss\\\",\\n    label_names=[\\\"image\\\", \\\"input_ids\\\"],\\n)\\n\\n# Create Trainer\\ntrainer = Trainer(\\n    model=model,\\n    args=training_args,\\n    train_dataset=trn_ds,\\n    eval_dataset=val_ds,\\n    optimizers=(optimizer, lr_scheduler),  # Pass your custom optimizer here.\\n)\\n# Train the model\\ntrainer.train()\\n\\n# Evaluate the model\\ntrainer.evaluate()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Define TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # Output directory where checkpoints and logs will be saved.\n",
    "    num_train_epochs=config.epochs,  # Total number of training epochs.\n",
    "    per_device_train_batch_size=config.batch_size,  # Batch size per GPU.\n",
    "    per_device_eval_batch_size=config.batch_size,  # Batch size for evaluation per GPU.\n",
    "    evaluation_strategy=\"steps\",  # Evaluation strategy (steps, epoch).\n",
    "    logging_strategy=\"steps\",  # Logging strategy (steps, epoch).\n",
    "    save_strategy=\"steps\",  # Save strategy (steps, epoch).\n",
    "    save_total_limit=2,  # Limit the total amount of checkpoints.\n",
    "    learning_rate=5e-5,  # Learning rate.\n",
    "    logging_steps=config.save_eval_and_logging_steps,\n",
    "    save_steps=config.save_eval_and_logging_steps,  # Save checkpoints every N steps.\n",
    "    eval_steps=config.save_eval_and_logging_steps,  # Evaluate every N steps.\n",
    "    logging_dir=\"./logs\",  # Directory for storing logs.\n",
    "    metric_for_best_model=\"loss\",\n",
    "    label_names=[\"image\", \"input_ids\"],\n",
    ")\n",
    "\n",
    "# Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=trn_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    optimizers=(optimizer, lr_scheduler),  # Pass your custom optimizer here.\n",
    ")\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yyr/anaconda3/envs/mcvp-book/lib/python3.8/site-packages/nbdev/export.py:54: UserWarning: Notebook '/mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/nbs/02.00_training.ipynb' uses `#|export` without `#|default_exp` cell.\n",
      "Note nbdev2 no longer supports nbdev1 syntax. Run `nbdev_migrate` to upgrade.\n",
      "See https://nbdev.fast.ai/getting_started.html for more information.\n",
      "  warn(f\"Notebook '{nbname}' uses `#|export` without `#|default_exp` cell.\\n\"\n",
      "Skipping .ipynb files as Jupyter dependencies are not installed.\n",
      "You can fix this by running ``pip install \"black[jupyter]\"``\n",
      "reformatted /mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/clip/core.py\n",
      "reformatted /mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/clip/config.py\n",
      "reformatted /mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/clip/_modidx.py\n",
      "reformatted /mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/clip/dataset.py\n",
      "reformatted /mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/clip/models.py\n",
      "\n",
      "All done! ‚ú® üç∞ ‚ú®\n",
      "5 files reformatted, 3 files left unchanged.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/home/yyr/anaconda3/envs/mcvp-book/bin/black', '../'], returncode=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# | hide\\nimport nbdev\\nnbdev.nbdev_export()\\nimport subprocess\\n\\nsubprocess.run([\\\"/home/yyr/anaconda3/envs/mcvp-book/bin/black\\\", __root])\";\n",
       "                var nbb_formatted_code = \"# | hide\\nimport nbdev\\n\\nnbdev.nbdev_export()\\nimport subprocess\\n\\nsubprocess.run([\\\"/home/yyr/anaconda3/envs/mcvp-book/bin/black\\\", __root])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | hide\n",
    "\n",
    "import nbdev\n",
    "nbdev.nbdev_export()\n",
    "import subprocess\n",
    "\n",
    "subprocess.run([\"/home/yyr/anaconda3/envs/mcvp-book/bin/black\", __root])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
