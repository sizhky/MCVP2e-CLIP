{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer\n",
    "\n",
    "> Dev notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# | hide\\n%reload_ext autoreload\\n%reload_ext nb_black\\n%autoreload 2\\nfrom nbdev.showdoc import *\\nimport sys\\n\\n__root = \\\"../\\\"\\nsys.path.append(__root)\";\n",
       "                var nbb_formatted_code = \"# | hide\\n%reload_ext autoreload\\n%reload_ext nb_black\\n%autoreload 2\\nfrom nbdev.showdoc import *\\nimport sys\\n\\n__root = \\\"../\\\"\\nsys.path.append(__root)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | hide\n",
    "%reload_ext autoreload\n",
    "%reload_ext nb_black\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *\n",
    "import sys\n",
    "\n",
    "__root = \"../\"\n",
    "sys.path.append(__root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# | export\\nfrom torch_snippets import *\\nfrom clip.dataset import DistilBertTokenizer\";\n",
       "                var nbb_formatted_code = \"# | export\\nfrom torch_snippets import *\\nfrom clip.dataset import DistilBertTokenizer\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | export\n",
    "from torch_snippets import *\n",
    "from clip.dataset import DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# | export\\n@torch.no_grad()\\ndef get_image_embeddings(val_dl, model):\\n    model.eval()\\n    valid_image_embeddings = []\\n    for batch in track2(val_dl):\\n        image_features = model.image_encoder(batch[\\\"image\\\"].to(model.config.device))\\n        image_embeddings = model.image_projection(image_features)\\n        valid_image_embeddings.append(image_embeddings)\\n    return torch.cat(valid_image_embeddings)\\n\\n\\n@torch.no_grad()\\ndef find_matches(model, image_embeddings, query, image_filenames):\\n    tokenizer = DistilBertTokenizer.from_pretrained(\\n        model.config.distilbert_text_tokenizer\\n    )\\n    encoded_query = tokenizer([query])\\n    batch = {\\n        key: torch.tensor(values).to(model.config.device)\\n        for key, values in encoded_query.items()\\n    }\\n    text_features = model.text_encoder(\\n        input_ids=batch[\\\"input_ids\\\"], attention_mask=batch[\\\"attention_mask\\\"]\\n    )\\n    text_embeddings = model.text_projection(text_features)\\n\\n    image_embeddings_n = F.normalize(image_embeddings, p=2, dim=-1)\\n    text_embeddings_n = F.normalize(text_embeddings, p=2, dim=-1)\\n    dot_similarity = text_embeddings_n @ image_embeddings_n.T\\n\\n    values, indices = torch.topk(dot_similarity.squeeze(0), 45)\\n    matches = [image_filenames[idx] for idx in indices[::5]]\\n    matches = [f\\\"{model.config.image_path}/{match}\\\" for match in matches]\\n    subplots(matches, nc=3, figsize=(10, 10))\";\n",
       "                var nbb_formatted_code = \"# | export\\n@torch.no_grad()\\ndef get_image_embeddings(val_dl, model):\\n    model.eval()\\n    valid_image_embeddings = []\\n    for batch in track2(val_dl):\\n        image_features = model.image_encoder(batch[\\\"image\\\"].to(model.config.device))\\n        image_embeddings = model.image_projection(image_features)\\n        valid_image_embeddings.append(image_embeddings)\\n    return torch.cat(valid_image_embeddings)\\n\\n\\n@torch.no_grad()\\ndef find_matches(model, image_embeddings, query, image_filenames):\\n    tokenizer = DistilBertTokenizer.from_pretrained(\\n        model.config.distilbert_text_tokenizer\\n    )\\n    encoded_query = tokenizer([query])\\n    batch = {\\n        key: torch.tensor(values).to(model.config.device)\\n        for key, values in encoded_query.items()\\n    }\\n    text_features = model.text_encoder(\\n        input_ids=batch[\\\"input_ids\\\"], attention_mask=batch[\\\"attention_mask\\\"]\\n    )\\n    text_embeddings = model.text_projection(text_features)\\n\\n    image_embeddings_n = F.normalize(image_embeddings, p=2, dim=-1)\\n    text_embeddings_n = F.normalize(text_embeddings, p=2, dim=-1)\\n    dot_similarity = text_embeddings_n @ image_embeddings_n.T\\n\\n    values, indices = torch.topk(dot_similarity.squeeze(0), 45)\\n    matches = [image_filenames[idx] for idx in indices[::5]]\\n    matches = [f\\\"{model.config.image_path}/{match}\\\" for match in matches]\\n    subplots(matches, nc=3, figsize=(10, 10))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | export\n",
    "@torch.no_grad()\n",
    "def get_image_embeddings(val_dl, model):\n",
    "    model.eval()\n",
    "    valid_image_embeddings = []\n",
    "    for batch in track2(val_dl):\n",
    "        image_features = model.image_encoder(batch[\"image\"].to(model.config.device))\n",
    "        image_embeddings = model.image_projection(image_features)\n",
    "        valid_image_embeddings.append(image_embeddings)\n",
    "    return torch.cat(valid_image_embeddings)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def find_matches(model, image_embeddings, query, image_filenames):\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "        model.config.distilbert_text_tokenizer\n",
    "    )\n",
    "    encoded_query = tokenizer([query])\n",
    "    batch = {\n",
    "        key: torch.tensor(values).to(model.config.device)\n",
    "        for key, values in encoded_query.items()\n",
    "    }\n",
    "    text_features = model.text_encoder(\n",
    "        input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n",
    "    )\n",
    "    text_embeddings = model.text_projection(text_features)\n",
    "\n",
    "    image_embeddings_n = F.normalize(image_embeddings, p=2, dim=-1)\n",
    "    text_embeddings_n = F.normalize(text_embeddings, p=2, dim=-1)\n",
    "    dot_similarity = text_embeddings_n @ image_embeddings_n.T\n",
    "\n",
    "    values, indices = torch.topk(dot_similarity.squeeze(0), 45)\n",
    "    matches = [image_filenames[idx] for idx in indices[::5]]\n",
    "    matches = [f\"{model.config.image_path}/{match}\" for match in matches]\n",
    "    subplots(matches, nc=3, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yyr/anaconda3/envs/mcvp-book/lib/python3.8/site-packages/nbdev/export.py:54: UserWarning: Notebook '/mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/nbs/02.00_training.ipynb' uses `#|export` without `#|default_exp` cell.\n",
      "Note nbdev2 no longer supports nbdev1 syntax. Run `nbdev_migrate` to upgrade.\n",
      "See https://nbdev.fast.ai/getting_started.html for more information.\n",
      "  warn(f\"Notebook '{nbname}' uses `#|export` without `#|default_exp` cell.\\n\"\n",
      "Skipping .ipynb files as Jupyter dependencies are not installed.\n",
      "You can fix this by running ``pip install \"black[jupyter]\"``\n",
      "reformatted /mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/clip/core.py\n",
      "reformatted /mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/clip/config.py\n",
      "reformatted /mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/clip/infer.py\n",
      "reformatted /mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/clip/_modidx.py\n",
      "reformatted /mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/clip/dataset.py\n",
      "reformatted /mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/clip/models.py\n",
      "\n",
      "All done! ✨ 🍰 ✨\n",
      "6 files reformatted, 3 files left unchanged.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/home/yyr/anaconda3/envs/mcvp-book/bin/black', '../'], returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# | hide\\n\\nimport nbdev\\nnbdev.nbdev_export()\\nimport subprocess\\n\\nsubprocess.run([\\\"/home/yyr/anaconda3/envs/mcvp-book/bin/black\\\", __root])\";\n",
       "                var nbb_formatted_code = \"# | hide\\n\\nimport nbdev\\n\\nnbdev.nbdev_export()\\nimport subprocess\\n\\nsubprocess.run([\\\"/home/yyr/anaconda3/envs/mcvp-book/bin/black\\\", __root])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | hide\n",
    "\n",
    "import nbdev\n",
    "nbdev.nbdev_export()\n",
    "import subprocess\n",
    "\n",
    "subprocess.run([\"/home/yyr/anaconda3/envs/mcvp-book/bin/black\", __root])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcvp-book",
   "language": "python",
   "name": "mcvp-book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
