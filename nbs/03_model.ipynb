{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "> Dev notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# | hide\\n%reload_ext autoreload\\n%reload_ext nb_black\\n%autoreload 2\\n%env CUDA_VISIBLE_DEVICES=\\n\\nfrom nbdev.showdoc import *\\nimport sys\\n\\n__root = \\\"../\\\"\\nsys.path.append(__root)\";\n",
       "                var nbb_formatted_code = \"# | hide\\n%reload_ext autoreload\\n%reload_ext nb_black\\n%autoreload 2\\n%env CUDA_VISIBLE_DEVICES=\\n\\nfrom nbdev.showdoc import *\\nimport sys\\n\\n__root = \\\"../\\\"\\nsys.path.append(__root)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | hide\n",
    "%reload_ext autoreload\n",
    "%reload_ext nb_black\n",
    "%autoreload 2\n",
    "%env CUDA_VISIBLE_DEVICES=\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "import sys\n",
    "\n",
    "__root = \"../\"\n",
    "sys.path.append(__root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# | export\\nfrom torch_snippets import *\\nfrom clip.core import *\";\n",
       "                var nbb_formatted_code = \"# | export\\nfrom torch_snippets import *\\nfrom clip.core import *\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | export\n",
    "from torch_snippets import *\n",
    "from clip.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# | export\\nimport timm\\nfrom transformers import DistilBertModel, DistilBertConfig\";\n",
       "                var nbb_formatted_code = \"# | export\\nimport timm\\nfrom transformers import DistilBertModel, DistilBertConfig\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | export\n",
    "import timm\n",
    "from transformers import DistilBertModel, DistilBertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"#| export\\nclass ImageEncoder(nn.Module):\\n    \\\"\\\"\\\"\\n    Encode images to a fixed size vector\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, config):\\n        super().__init__()\\n        self.model = timm.create_model(\\n            config.model_name, config.pretrained, num_classes=0, global_pool=\\\"avg\\\"\\n        )\\n        for p in self.model.parameters():\\n            p.requires_grad = config.trainable\\n\\n    def forward(self, x):\\n        return self.model(x)\\n\\n\\nclass TextEncoder(nn.Module):\\n    def __init__(self, config):\\n        super().__init__()\\n        if config.pretrained:\\n            self.model = DistilBertModel.from_pretrained(config.distilbert_text_encoder_model)\\n        else:\\n            self.model = DistilBertModel(config=DistilBertConfig())\\n        for p in self.model.parameters():\\n            p.requires_grad = config.trainable\\n        self.target_token_idx = config.target_token_idx\\n\\n    def forward(self, input_ids, attention_mask):\\n        output = self.model(input_ids=input_ids, attention_mask=attention_mask)\\n        last_hidden_state = output.last_hidden_state\\n        return last_hidden_state[:, self.target_token_idx, :]\\n\\n\\nclass ProjectionHead(nn.Module):\\n    def __init__(self, embedding_dim, config):\\n        super().__init__()\\n        self.projection = nn.Linear(embedding_dim, config.projection_dim)\\n        self.gelu = nn.GELU()\\n        self.fc = nn.Linear(config.projection_dim, config.projection_dim)\\n        self.dropout = nn.Dropout(config.dropout)\\n        self.layer_norm = nn.LayerNorm(config.projection_dim)\\n\\n    def forward(self, x):\\n        projected = self.projection(x)\\n        x = self.gelu(projected)\\n        x = self.fc(x)\\n        x = self.dropout(x)\\n        x = x + projected\\n        x = self.layer_norm(x)\\n        return x\\n\\n\\nclass CLIP(nn.Module):\\n    def __init__(self, config):\\n        super().__init__()\\n        self.config = config\\n        self.image_encoder = ImageEncoder(config)\\n        self.text_encoder = TextEncoder(config)\\n        self.image_projection = ProjectionHead(config.image_embedding, config)\\n        self.text_projection = ProjectionHead(config.text_embedding, config)\\n        self.temperature = config.temperature\\n\\n    def forward(self, image, input_ids, attention_mask):\\n        # Getting Image and Text Features\\n        image_features = self.image_encoder(image)\\n        text_features = self.text_encoder(\\n            input_ids=input_ids, attention_mask=attention_mask\\n        )\\n        # Getting Image and Text Embeddings (with same dimension)\\n        image_embeddings = self.image_projection(image_features)\\n        text_embeddings = self.text_projection(text_features)\\n        # Calculating the Loss\\n        logits = (text_embeddings @ image_embeddings.T) / self.temperature\\n        images_similarity = image_embeddings @ image_embeddings.T\\n        texts_similarity = text_embeddings @ text_embeddings.T\\n        targets = F.softmax(\\n            (images_similarity + texts_similarity) / 2 * self.temperature, dim=-1\\n        )\\n        texts_loss = cross_entropy(logits, targets, reduction=\\\"none\\\")\\n        images_loss = cross_entropy(logits.T, targets.T, reduction=\\\"none\\\")\\n        loss = (images_loss + texts_loss) / 2.0  # shape: (batch_size)\\n        return {'loss': loss.mean()}\\n    \\n    @classmethod\\n    def from_pretrained(cls, folder, config):\\n        model = cls(config)\\n        load_torch_model_weights_to(model, P(folder)/'pytorch_model.bin')\\n        return model\\n        \\n\\ndef cross_entropy(preds, targets, reduction=\\\"none\\\"):\\n    log_softmax = nn.LogSoftmax(dim=-1)\\n    loss = (-targets * log_softmax(preds)).sum(1)\\n    if reduction == \\\"none\\\":\\n        return loss\\n    elif reduction == \\\"mean\\\":\\n        return loss.mean()\";\n",
       "                var nbb_formatted_code = \"# | export\\nclass ImageEncoder(nn.Module):\\n    \\\"\\\"\\\"\\n    Encode images to a fixed size vector\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, config):\\n        super().__init__()\\n        self.model = timm.create_model(\\n            config.model_name, config.pretrained, num_classes=0, global_pool=\\\"avg\\\"\\n        )\\n        for p in self.model.parameters():\\n            p.requires_grad = config.trainable\\n\\n    def forward(self, x):\\n        return self.model(x)\\n\\n\\nclass TextEncoder(nn.Module):\\n    def __init__(self, config):\\n        super().__init__()\\n        if config.pretrained:\\n            self.model = DistilBertModel.from_pretrained(\\n                config.distilbert_text_encoder_model\\n            )\\n        else:\\n            self.model = DistilBertModel(config=DistilBertConfig())\\n        for p in self.model.parameters():\\n            p.requires_grad = config.trainable\\n        self.target_token_idx = config.target_token_idx\\n\\n    def forward(self, input_ids, attention_mask):\\n        output = self.model(input_ids=input_ids, attention_mask=attention_mask)\\n        last_hidden_state = output.last_hidden_state\\n        return last_hidden_state[:, self.target_token_idx, :]\\n\\n\\nclass ProjectionHead(nn.Module):\\n    def __init__(self, embedding_dim, config):\\n        super().__init__()\\n        self.projection = nn.Linear(embedding_dim, config.projection_dim)\\n        self.gelu = nn.GELU()\\n        self.fc = nn.Linear(config.projection_dim, config.projection_dim)\\n        self.dropout = nn.Dropout(config.dropout)\\n        self.layer_norm = nn.LayerNorm(config.projection_dim)\\n\\n    def forward(self, x):\\n        projected = self.projection(x)\\n        x = self.gelu(projected)\\n        x = self.fc(x)\\n        x = self.dropout(x)\\n        x = x + projected\\n        x = self.layer_norm(x)\\n        return x\\n\\n\\nclass CLIP(nn.Module):\\n    def __init__(self, config):\\n        super().__init__()\\n        self.config = config\\n        self.image_encoder = ImageEncoder(config)\\n        self.text_encoder = TextEncoder(config)\\n        self.image_projection = ProjectionHead(config.image_embedding, config)\\n        self.text_projection = ProjectionHead(config.text_embedding, config)\\n        self.temperature = config.temperature\\n\\n    def forward(self, image, input_ids, attention_mask):\\n        # Getting Image and Text Features\\n        image_features = self.image_encoder(image)\\n        text_features = self.text_encoder(\\n            input_ids=input_ids, attention_mask=attention_mask\\n        )\\n        # Getting Image and Text Embeddings (with same dimension)\\n        image_embeddings = self.image_projection(image_features)\\n        text_embeddings = self.text_projection(text_features)\\n        # Calculating the Loss\\n        logits = (text_embeddings @ image_embeddings.T) / self.temperature\\n        images_similarity = image_embeddings @ image_embeddings.T\\n        texts_similarity = text_embeddings @ text_embeddings.T\\n        targets = F.softmax(\\n            (images_similarity + texts_similarity) / 2 * self.temperature, dim=-1\\n        )\\n        texts_loss = cross_entropy(logits, targets, reduction=\\\"none\\\")\\n        images_loss = cross_entropy(logits.T, targets.T, reduction=\\\"none\\\")\\n        loss = (images_loss + texts_loss) / 2.0  # shape: (batch_size)\\n        return {\\\"loss\\\": loss.mean()}\\n\\n    @classmethod\\n    def from_pretrained(cls, folder, config):\\n        model = cls(config)\\n        load_torch_model_weights_to(model, P(folder) / \\\"pytorch_model.bin\\\")\\n        return model\\n\\n\\ndef cross_entropy(preds, targets, reduction=\\\"none\\\"):\\n    log_softmax = nn.LogSoftmax(dim=-1)\\n    loss = (-targets * log_softmax(preds)).sum(1)\\n    if reduction == \\\"none\\\":\\n        return loss\\n    elif reduction == \\\"mean\\\":\\n        return loss.mean()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "class ImageEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encode images to a fixed size vector\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(\n",
    "            config.model_name, config.pretrained, num_classes=0, global_pool=\"avg\"\n",
    "        )\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = config.trainable\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        if config.pretrained:\n",
    "            self.model = DistilBertModel.from_pretrained(config.distilbert_text_encoder_model)\n",
    "        else:\n",
    "            self.model = DistilBertModel(config=DistilBertConfig())\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = config.trainable\n",
    "        self.target_token_idx = config.target_token_idx\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = output.last_hidden_state\n",
    "        return last_hidden_state[:, self.target_token_idx, :]\n",
    "\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, embedding_dim, config):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Linear(embedding_dim, config.projection_dim)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.fc = nn.Linear(config.projection_dim, config.projection_dim)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.layer_norm = nn.LayerNorm(config.projection_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        projected = self.projection(x)\n",
    "        x = self.gelu(projected)\n",
    "        x = self.fc(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + projected\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CLIP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.image_encoder = ImageEncoder(config)\n",
    "        self.text_encoder = TextEncoder(config)\n",
    "        self.image_projection = ProjectionHead(config.image_embedding, config)\n",
    "        self.text_projection = ProjectionHead(config.text_embedding, config)\n",
    "        self.temperature = config.temperature\n",
    "\n",
    "    def forward(self, image, input_ids, attention_mask):\n",
    "        # Getting Image and Text Features\n",
    "        image_features = self.image_encoder(image)\n",
    "        text_features = self.text_encoder(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "        # Getting Image and Text Embeddings (with same dimension)\n",
    "        image_embeddings = self.image_projection(image_features)\n",
    "        text_embeddings = self.text_projection(text_features)\n",
    "        # Calculating the Loss\n",
    "        logits = (text_embeddings @ image_embeddings.T) / self.temperature\n",
    "        images_similarity = image_embeddings @ image_embeddings.T\n",
    "        texts_similarity = text_embeddings @ text_embeddings.T\n",
    "        targets = F.softmax(\n",
    "            (images_similarity + texts_similarity) / 2 * self.temperature, dim=-1\n",
    "        )\n",
    "        texts_loss = cross_entropy(logits, targets, reduction=\"none\")\n",
    "        images_loss = cross_entropy(logits.T, targets.T, reduction=\"none\")\n",
    "        loss = (images_loss + texts_loss) / 2.0  # shape: (batch_size)\n",
    "        return {'loss': loss.mean()}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, folder, config):\n",
    "        model = cls(config)\n",
    "        load_torch_model_weights_to(model, P(folder)/'pytorch_model.bin')\n",
    "        return model\n",
    "        \n",
    "\n",
    "def cross_entropy(preds, targets, reduction=\"none\"):\n",
    "    log_softmax = nn.LogSoftmax(dim=-1)\n",
    "    loss = (-targets * log_softmax(preds)).sum(1)\n",
    "    if reduction == \"none\":\n",
    "        return loss\n",
    "    elif reduction == \"mean\":\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping .ipynb files as Jupyter dependencies are not installed.\n",
      "You can fix this by running ``pip install \"black[jupyter]\"``\n",
      "reformatted /mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/clip/core.py\n",
      "reformatted /mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/clip/config.py\n",
      "reformatted /mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/clip/_modidx.py\n",
      "reformatted /mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/clip/dataset.py\n",
      "reformatted /mnt/347832F37832B388/projects/MCVP2e/Chapter-15b/CLIP/clip/models.py\n",
      "\n",
      "All done! ✨ 🍰 ✨\n",
      "5 files reformatted, 3 files left unchanged.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/home/yyr/anaconda3/envs/mcvp-book/bin/black', '../'], returncode=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# | hide\\nimport nbdev\\nnbdev.nbdev_export()\\nimport subprocess\\n\\nsubprocess.run([\\\"/home/yyr/anaconda3/envs/mcvp-book/bin/black\\\", __root])\";\n",
       "                var nbb_formatted_code = \"# | hide\\nimport nbdev\\n\\nnbdev.nbdev_export()\\nimport subprocess\\n\\nsubprocess.run([\\\"/home/yyr/anaconda3/envs/mcvp-book/bin/black\\\", __root])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "nbdev.nbdev_export()\n",
    "import subprocess\n",
    "\n",
    "subprocess.run([\"/home/yyr/anaconda3/envs/mcvp-book/bin/black\", __root])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcvp-book",
   "language": "python",
   "name": "mcvp-book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
